\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Sporns2005}
\citation{Hagmann2005}
\citation{scipy}
\citation{scikitlearn}
\citation{matplotlib}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Objectives}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Public code and data}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{1}{section.2}}
\citation{Bellec2010}
\citation{Collins1998}
\citation{Fonov2011}
\citation{Zijdenbos2002}
\citation{Power2012}
\citation{Lund2006}
\citation{Giove2009}
\citation{Bellec2010a}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Dataset}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Preprocessing and feature extraction}{2}{subsection.2.2}}
\citation{Gilad-bachrach2004}
\citation{Gilad-bachrach2004}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Exemple of the connectomes for one subject at scale 7, 12, 20, 36, 64, 122, 197, 325 and 444.}}{3}{figure.1}}
\newlabel{fig_connectomes3x3}{{1}{3}{Exemple of the connectomes for one subject at scale 7, 12, 20, 36, 64, 122, 197, 325 and 444}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Calibrating the problem}{3}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Preprocessing and confounds regression}{3}{subsection.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Optimal functional scale}{3}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Multiscale bagging predictions}{3}{subsection.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}I-Relief margin optimization}{3}{subsection.2.7}}
\citation{Gilad-bachrach2004}
\citation{Sun2007}
\citation{Hanke2009}
\citation{Sun2007}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Pipeline of the modified bagging procedure using multiscale functional connectomes.}}{4}{figure.2}}
\newlabel{fig_bagging_multiscale}{{2}{4}{Pipeline of the modified bagging procedure using multiscale functional connectomes}{figure.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Greedy feature flip}}{4}{algocf.1}}
\newlabel{algo_gflip}{{1}{4}{I-Relief margin optimization}{ALC@unique.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Calibrating the problem}{4}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Normalization and confound variables}{4}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Calibration of the classification task: Receiver operating characteristic (ROC) curve of the 10 fold cross validation with the average of ROC curve. The legend show the respective AUC (area under the curve) of each fold and the average AUC. The classifier accuracy obtained was 64.53\%.}}{5}{figure.3}}
\newlabel{fig_calib_svm}{{3}{5}{Calibration of the classification task: Receiver operating characteristic (ROC) curve of the 10 fold cross validation with the average of ROC curve. The legend show the respective AUC (area under the curve) of each fold and the average AUC. The classifier accuracy obtained was 64.53\%}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Optimal scale}{5}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Multiscale}{5}{subsection.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}I-Relief}{5}{subsection.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 67.07\% accuracy after normalization and regression of the confounding variables.}}{5}{figure.4}}
\newlabel{fig_svc_norm_cnotopt}{{4}{5}{Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 67.07\% accuracy after normalization and regression of the confounding variables}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 69.89\% accuracy after normalization and regression of the confounding variables and parameter C optimized.}}{5}{figure.5}}
\newlabel{fig_svc_norm}{{5}{5}{Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 69.89\% accuracy after normalization and regression of the confounding variables and parameter C optimized}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Summary}{5}{subsection.3.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Accuracy scores of the tuned classifier of each functional scale using a 10-fold cross validation.}}{6}{figure.6}}
\newlabel{fig_scale_svm}{{6}{6}{Accuracy scores of the tuned classifier of each functional scale using a 10-fold cross validation}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 79.48\% accuracy using features from functional scale 197 after normalization and regression of the confounding variables and parameter C optimized using grid search.}}{6}{figure.7}}
\newlabel{fig_svc_norm_optimal_scale}{{7}{6}{Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 79.48\% accuracy using features from functional scale 197 after normalization and regression of the confounding variables and parameter C optimized using grid search}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion and conclusion}{6}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 80.14\% accuracy using multiscale bagging from scale 122, 197, 444; after normalization and regression of the confounding variables and parameter C optimized using grid search.}}{6}{figure.8}}
\newlabel{fig_svc_bagging_multiscale}{{8}{6}{Receiver operating characteristic (ROC) curve of the average 10-fold cross-validation. The legend show the expected AUC (area under the curve) obtained by luck and the average AUC from the classifier. Classifier obtained 80.14\% accuracy using multiscale bagging from scale 122, 197, 444; after normalization and regression of the confounding variables and parameter C optimized using grid search}{figure.8}{}}
\newlabel{tab_results}{{3.6}{6}{Summary}{subsection.3.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of the performance of each classification pipeline. Acronyms: calib: calibration, NC: normalized and regression of confounds (age and gender), Opt: optimisation of the classification parameter using nested 10-fold cross-validation. The multiscale bagging was performed on 3 scales (122, 197 and 444) and I-Relief was perform on the scale 197. }}{6}{table.1}}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,vision,cdansereau}
\bibcite{Sporns2005}{1}
\bibcite{Hagmann2005}{2}
\bibcite{scipy}{3}
\bibcite{scikitlearn}{4}
\bibcite{matplotlib}{5}
\bibcite{Bellec2010}{6}
\bibcite{Collins1998}{7}
\bibcite{Fonov2011}{8}
\bibcite{Zijdenbos2002}{9}
\bibcite{Power2012}{10}
\bibcite{Lund2006}{11}
\bibcite{Giove2009}{12}
\bibcite{Bellec2010a}{13}
\bibcite{Gilad-bachrach2004}{14}
\bibcite{Sun2007}{15}
\bibcite{Hanke2009}{16}
\@writefile{toc}{\contentsline {section}{References}{7}{section*.1}}
